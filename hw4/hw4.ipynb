{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 4: Logistic regression, hyperparameter optimization \n",
    "### Associated lectures: [Lectures 7, 8](https://github.com/UBC-CS/cpsc330-2022W2) \n",
    "\n",
    "**Due date: Feb 10, 11:59pm**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.556778Z",
     "start_time": "2023-02-11T01:43:40.047405Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:6}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- **Be kind** and respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
    "\n",
    "_Note: The assignments will get gradually more open-ended as we progress through the course. In many cases, there won't be a single correct solution. Sometimes you will have to make your own choices and your own decisions (for example, on what parameter values to use when they are not explicitly provided in the instructions). Use your own judgment in such cases and justify your choices, if necessary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Implementing `DummyClassifier` \n",
    "<hr>\n",
    "rubric={points:25}\n",
    "\n",
    "In this course (unlike CPSC 340) you will generally **not** be asked to implement machine learning algorihtms (like logistic regression) from scratch. However, this exercise is an exception: you will implement the simplest possible classifier, `DummyClassifier`.\n",
    "\n",
    "As a reminder, `DummyClassifier` is meant as a baseline and is generally the worst possible \"model\" you could \"fit\" to a dataset. All it does is predict the most popular class in the training set. So if there are more 0s than 1s it predicts 0 every time, and if there are more 1s than 0s it predicts 1 every time. For `predict_proba` it looks at the frequencies in the training set, so if you have 30% 0's 70% 1's it predicts `[0.3 0.7]` every time. Thus, `fit` only looks at `y` (not `X`).\n",
    "\n",
    "Below you will find starter code for a class called `MyDummyClassifier`, which has methods `fit()`, `predict()`, `predict_proba()` and `score()`. Your task is to fill in those four functions. To get your started, I have given you a `return` statement in each case that returns the correct data type: \n",
    "- `fit` can return nothing, \n",
    "- `predict` returns an array whose size is the number of examples, \n",
    "- `predict_proba` returns an array whose size is the number of examples x 2, and \n",
    "- `score` returns a number.\n",
    "\n",
    "The next code block has some tests you can use to assess whether your code is working. \n",
    "\n",
    "I suggest starting with `fit` and `predict`, and making sure those are working before moving on to `predict_proba`. For `predict_proba`, you should return the frequency of each class in the training data, which is the behaviour of `DummyClassifier(strategy='prior')`. Your `score` function should call your `predict` function. Again, you can compare with `DummyClassifier` using the code below.\n",
    "\n",
    "To simplify this question, you can assume **binary classification**, and furthermore that these classes are **encoded as 0 and 1**. In other words, you can assume that `y` contains only 0s and 1s. The real `DummyClassifier` works when you have more than two classes, and also works if the target values are encoded differently, for example as \"cat\", \"dog\", \"mouse\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.581635Z",
     "start_time": "2023-02-11T01:43:44.560513Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDummyClassifier:\n",
    "    \"\"\"\n",
    "    A baseline classifier that predicts the most common class.\n",
    "    The predicted probabilities come from the relative frequencies\n",
    "    of the classes in the training data.\n",
    "\n",
    "    This implementation only works when y only contains 0s and 1s.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        The implementation of this method is as follows:\n",
    "        - num_ones stores the number of ones in y\n",
    "        - proportion variable stores the proportion of ones in y\n",
    "        - self.prediction attribute stores 0 if the proportion of ones is less than half, 1 otherwise.\n",
    "        - self.probabilities stores an array of proportion of 0 and 1\n",
    "        \"\"\"\n",
    "        num_ones = np.array(y[y==1]).sum()\n",
    "        proportion = num_ones / len(y)\n",
    "        \n",
    "        self.prediction = 0 if proportion < 0.5 else 1\n",
    "        self.probabilities = [1-proportion, proportion]\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        The Implementation of this method can be explained as follows:\n",
    "        - predictions variable is an array of the most common label in y (stored in the self.prediction attribute)\n",
    "        - self.predictions attribute is the prediction variable turned into a numpy array\n",
    "        I made the self.predictions attribute to be a numpy array in order to take advantage of numpy array properties\n",
    "        \n",
    "        \"\"\"\n",
    "        predictions = [self.prediction] * len(X)\n",
    "        self.predictions = np.array(predictions)\n",
    "        return self.predictions\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        The implementation of this method can be explained as follows:\n",
    "        - proba is an array of the self.probabilities attribute. It has the same length as the length of X\n",
    "        - I returned a numpy array of proba to take advantage of numpy properties \n",
    "        \"\"\"\n",
    "        proba = [self.probabilities] * len(X)\n",
    "        return np.array(proba)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        The implementation of this method can be explained  as follows:\n",
    "        - scores is a numpy boolean array array. The entries are true if the prediction is the same as the actual\n",
    "        - I return a number which is the proportion of the predictions that were correct\n",
    "        \"\"\"\n",
    "        scores = (np.array(y) == self.prediction)\n",
    "        return sum(list(scores))/len(list(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some tests for `predict` using randomly generated data. You may want to run the cell a few times to make sure you explore the different cases (or automate this with a loop or random seeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.601082Z",
     "start_time": "2023-02-11T01:43:44.587663Z"
    }
   },
   "outputs": [],
   "source": [
    "# For testing, generate random data\n",
    "n_train = 101\n",
    "n_valid = 21\n",
    "d = 5\n",
    "X_train_dummy = np.random.randn(n_train, d)\n",
    "X_valid_dummy = np.random.randn(n_valid, d)\n",
    "y_train_dummy = np.random.randint(2, size=n_train)\n",
    "y_valid_dummy = np.random.randint(2, size=n_valid)\n",
    "\n",
    "my_dc = MyDummyClassifier()\n",
    "sk_dc = DummyClassifier(strategy=\"prior\")\n",
    "\n",
    "my_dc.fit(X_train_dummy, y_train_dummy)\n",
    "sk_dc.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "assert np.array_equal(my_dc.predict(X_train_dummy), sk_dc.predict(X_train_dummy))\n",
    "assert np.array_equal(my_dc.predict(X_valid_dummy), sk_dc.predict(X_valid_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some tests for `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.619485Z",
     "start_time": "2023-02-11T01:43:44.611811Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    my_dc.predict_proba(X_train_dummy), sk_dc.predict_proba(X_train_dummy)\n",
    ")\n",
    "assert np.allclose(\n",
    "    my_dc.predict_proba(X_valid_dummy), sk_dc.predict_proba(X_valid_dummy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some tests for `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.636858Z",
     "start_time": "2023-02-11T01:43:44.624568Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(\n",
    "    my_dc.score(X_train_dummy, y_train_dummy), sk_dc.score(X_train_dummy, y_train_dummy)\n",
    ")\n",
    "assert np.isclose(\n",
    "    my_dc.score(X_valid_dummy, y_valid_dummy), sk_dc.score(X_valid_dummy, y_valid_dummy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e3cc53df86a7e14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 2: Trump Tweets\n",
    "<hr>\n",
    "\n",
    "For the rest of this assignment we'll be looking at a [dataset of Donald Trump's tweets](https://www.kaggle.com/austinreese/trump-tweets) as of June 2020. You should start by downloading the dataset. Unzip it and move the file `realdonaldtrump.csv` into this directory. As usual, please do not submit the dataset when you submit the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.920406Z",
     "start_time": "2023-02-11T01:43:44.643170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1698308935</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701461182</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737479987</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741160716</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773561338</th>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         link  \\\n",
       "id                                                              \n",
       "1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
       "1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
       "1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
       "1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
       "\n",
       "                                                      content  \\\n",
       "id                                                              \n",
       "1698308935  Be sure to tune in and watch Donald Trump on L...   \n",
       "1701461182  Donald Trump will be appearing on The View tom...   \n",
       "1737479987  Donald Trump reads Top Ten Financial Tips on L...   \n",
       "1741160716  New Blog Post: Celebrity Apprentice Finale and...   \n",
       "1773561338  \"My persona will never be that of a wallflower...   \n",
       "\n",
       "                           date  retweets  favorites mentions hashtags  \n",
       "id                                                                      \n",
       "1698308935  2009-05-04 13:54:25       510        917      NaN      NaN  \n",
       "1701461182  2009-05-04 20:00:10        34        267      NaN      NaN  \n",
       "1737479987  2009-05-08 08:38:08        13         19      NaN      NaN  \n",
       "1741160716  2009-05-08 15:40:15        11         26      NaN      NaN  \n",
       "1773561338  2009-05-12 09:07:28      1375       1945      NaN      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"realdonaldtrump.csv\", index_col=0)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.931681Z",
     "start_time": "2023-02-11T01:43:44.922855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43352, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be trying to predict whether a tweet will go \"viral\", defined as having more than 10,000 retweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.946426Z",
     "start_time": "2023-02-11T01:43:44.935672Z"
    }
   },
   "outputs": [],
   "source": [
    "y = tweets_df[\"retweets\"] > 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, we'll be using only the content (text) of the tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:44.957062Z",
     "start_time": "2023-02-11T01:43:44.950640Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tweets_df[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this assignment, you can ignore all the other columns in the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2(a) ordering the steps\n",
    "rubric={points:8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building a model using `CountVectorizer` and `LogisticRegression`. The code required to do this has been provided below, but in the wrong order. \n",
    "\n",
    "- Rearrange the lines of code to correctly fit the model and compute the cross-validation score. \n",
    "- Add a short comment to each block to describe what the code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:57.218217Z",
     "start_time": "2023-02-11T01:43:44.987488Z"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       1.681678\n",
       "score_time     0.149308\n",
       "test_score     0.898475\n",
       "train_score    0.967952\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111)\n",
    "\n",
    "# Creating a CountVectorizer object for bag of words representation\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Initializing a logistic regression model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Creating a pipeline for the preprocessing step and the logistic regression model\n",
    "pipe = make_pipeline(countvec, lr)\n",
    "\n",
    "# Performing a 5-fold crossvalidation, storing results in a pandas dataframe\n",
    "cross_val_results = pd.DataFrame(\n",
    "    cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    ")\n",
    "\n",
    "\n",
    "# Outputing the average scores(train score and validation score) and times(score time and fit time)\n",
    "cross_val_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(b) Cross-validation fold sub-scores\n",
    "rubric={points:3}\n",
    "\n",
    "Above we averaged the scores from the 5 folds of cross-validation. \n",
    "\n",
    "- Print out the 5 individual scores. \n",
    "    - (Reminder: `sklearn` calls them `\"test_score\"` but they are really (cross-)validation scores.)\n",
    "- Are the 5 scores close to each other or spread far apart? \n",
    "  - (This is a bit subjective, answer to the best of your ability.)\n",
    "- How does the size of this dataset (number of rows) compare to the cities dataset we have been using in class? How does this relate to the different sub-scores from the 5 folds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:57.237600Z",
     "start_time": "2023-02-11T01:43:57.221354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>validation score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966976</td>\n",
       "      <td>0.895587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.898047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.967975</td>\n",
       "      <td>0.896971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.897893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967938</td>\n",
       "      <td>0.903876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  validation score\n",
       "0     0.966976          0.895587\n",
       "1     0.968206          0.898047\n",
       "2     0.967975          0.896971\n",
       "3     0.968667          0.897893\n",
       "4     0.967938          0.903876"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_results[['train_score', 'test_score']].rename(columns={'test_score': 'validation score'})\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe above, we see that the results do not spread far apart. The validation scores are around the 90% mark while the train scores are around the 96% mark. This is a much better performance than the on the dataset  in the lecture. This is because, This is a much larger dataset, and hence, on every fold, it is able to train on more data, giving it a better understanding of the distributions, hence performing better on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(c) baseline\n",
    "rubric={points:3}\n",
    "\n",
    "By the way, are these scores any good? \n",
    "\n",
    "- Run `DummyClassifier` (or `MyDummyClassifier`!) on this dataset.\n",
    "- Compare the `DummyClassifier` score to what you got from logistic regression above. Does logistic regression seem to be doing anything useful?\n",
    "- Is it necessary to use `CountVectorizer` here? Briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:57.422910Z",
     "start_time": "2023-02-11T01:43:57.241010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Train Score: 0.735\n",
      "Dummy Test Score: 0.741\n"
     ]
    }
   ],
   "source": [
    "dummy_model = MyDummyClassifier()\n",
    "dummy_model.fit(X_train, y_train)\n",
    "train_score = dummy_model.score(X_train, y_train)\n",
    "test_score = dummy_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Dummy Train Score: {train_score:.3f}\\n\"\\\n",
    "      f\"Dummy Test Score: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model performs much better than the dummy model. \n",
    "It is not necessary to include `CountVectorizer` because the dummy model doesnt care about the content of the predictors (the text). It only picks the most common label in the `y` column. It would be of no importance to vectorize the text since the y column is the same for both processed and unprocessed dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba1f8ea22638cf75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### 2(d) probability scores\n",
    "rubric={points:5}\n",
    "\n",
    "Here we train a logistic regression classifier on the entire training set: \n",
    "\n",
    "(Note: this is relying on the `pipe` variable from 2(a) - you'll need to redefine it if you overwrote that variable in between.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:59.468758Z",
     "start_time": "2023-02-11T01:43:57.426128Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model, find the tweet in the **test set** with the highest predicted probability of being viral. Print out the tweet and the associated probability score.\n",
    "\n",
    "Reminder: you are free to reuse/adapt code from lecture. Please add in a small attribution, e.g. \"From Lecture 7\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:59.979596Z",
     "start_time": "2023-02-11T01:43:59.471138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Score: 0.9999996937246393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“FBI texts have revealed anti-Trump Bias.” @ FoxNews Big News, but the Fake News doesn’t want to cover. Total corruption - the Witch Hunt has turned out to be a scam! At some point soon the Mainstream Media will have to cover correctly, too big a story!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtainig Probability scores as a numpy array\n",
    "predict_proba_numpy = pipe.predict_proba(X_test)\n",
    "\n",
    "# Changing predict_proba scores to pandas dataframe and taking the second column\n",
    "predict_proba_df = pd.DataFrame(pipe.predict_proba(X_test))[1]\n",
    "\n",
    "# Obtaining the index of the largest probability of going viral\n",
    "max_value_index = np.argmax(predict_proba_df)\n",
    "\n",
    "# Obtaining the tweet with at the index as a pandas dataframe\n",
    "tweet_df = pd.DataFrame(pd.DataFrame(X_test).iloc[max_value_index]).T.reset_index()[\"content\"]\n",
    "\n",
    "# Printing the probability score\n",
    "print(f\"Probability Score: {predict_proba_df[max_value_index]}\")\n",
    "\n",
    "# Outputting the tweet as a string\n",
    "tweet_df.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f910e9d1d6d09182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2(e) coefficients\n",
    "rubric={points:4}\n",
    "\n",
    "We can extract the `CountVectorizer` and `LogisticRegression` objects from the `make_pipeline` object as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:43:59.992237Z",
     "start_time": "2023-02-11T01:43:59.982074Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_from_pipe = pipe.named_steps[\"countvectorizer\"]\n",
    "lr_from_pipe = pipe.named_steps[\"logisticregression\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these extracted components above, display\n",
    "- the 5 words with the highest coefficients and \n",
    "- the 5 words with the smallest coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:44:00.103669Z",
     "start_time": "2023-02-11T01:43:59.995729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Highest Coefficient Words</th>\n",
       "      <th>Lowest Coefficient Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obamagate</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harassment</td>\n",
       "      <td>trump2016pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>barackobama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mini</td>\n",
       "      <td>donaldtrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake</td>\n",
       "      <td>celebapprentice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Highest Coefficient Words Lowest Coefficient Words\n",
       "0                 obamagate          realdonaldtrump\n",
       "1                harassment             trump2016pic\n",
       "2               coronavirus              barackobama\n",
       "3                      mini              donaldtrump\n",
       "4                      fake          celebapprentice"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "# Obtainig the Coefficients as a numpy array\n",
    "lr_coeffs: np.array = lr_from_pipe.coef_[0]\n",
    "\n",
    "# Creating a python list that with an enumeration of the coefficients\n",
    "lr_index_coeffs: List[tuple] = [(coef, num) for num, coef in enumerate(lr_coeffs)]\n",
    "\n",
    "# Sorting the list from largest coefficient to the lowest\n",
    "lr_index_coeffs.sort(key= lambda x: x[0], reverse=True)\n",
    "\n",
    "# Obtaining the 5 largest coefficients and their indices as a list of tuples\n",
    "top_5: List[tuple] = lr_index_coeffs[:5]\n",
    "\n",
    "# Obtaining the bottom 5 coefficients and their indices as a list of tuples\n",
    "bottom_5: List[tuple] = list(reversed(lr_index_coeffs[-5:]))\n",
    "\n",
    "# Obtaining just the indices of the highest coefficients\n",
    "tops: List[int] = [index for coef, index in top_5]\n",
    "\n",
    "# Obtaining just the indices of the lowest coefficients\n",
    "bottoms: List[int] = [index for coef, index in bottom_5]\n",
    "\n",
    "# Creating a dictionary whose contents are the vocabulary. The keys and values are reversed\n",
    "new_vocab = {word: index for index, word in vec_from_pipe.vocabulary_.items()}\n",
    "\n",
    "# Obtaining the words with the highest coefficients as a python list\n",
    "highest_coefficient_words: List[str] = [new_vocab[index] for index in tops]\n",
    "\n",
    "# Obtaining the words with the lowest coefficients as a python list of strings\n",
    "lowest_coefficient_words: List[str] = [new_vocab[index] for index in bottoms]\n",
    "\n",
    "# Putting them in a form of a pandas dataframe\n",
    "extracts_df: pd.DataFrame = pd.DataFrame({\"Highest Coefficient Words\": highest_coefficient_words,\n",
    "                           \"Lowest Coefficient Words\": lowest_coefficient_words})\n",
    "    \n",
    "# Displaying the results\n",
    "extracts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2(f) Running a cross-validation fold without sklearn tools \n",
    "rubric={points:8}\n",
    "\n",
    "Sklearn provides a lot of useful tools like `make_pipeline` and `cross_validate`, which are awesome. But with these fancy tools it's also easy to lose track of what is actually happening under the hood. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Compute logistic regression's validation score on the first fold, that is, train on 80% and validate on 20% of the training data (`X_train`) without using sklearn `Pipeline` or `cross_validate` or `cross_val_score`. Store the score of the fold in a variable called `fold_score`. Recall that `cross_validation` in `sklearn` does not shuffle the data by default.    \n",
    "\n",
    "You should start with the following `CountVectorizer` and `LogisticRegression` objects, as well as `X_train` and `y_train` (which you should further split with `train_test_split` and `shuffle=False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:44:01.884764Z",
     "start_time": "2023-02-11T01:44:00.108712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer object\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Logistic Regression Model Initialization\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Splitting Data\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train, y_train, \n",
    "                                                                  test_size=0.2, shuffle=False)\n",
    "\n",
    "# Fitting `countvec` and transforming the count vectorizer on the training split\n",
    "X_train_split = countvec.fit_transform(X_train_split)\n",
    "\n",
    "# Transforming test split\n",
    "X_valid = countvec.transform(X_valid)\n",
    "\n",
    "# Fitting Logistic regression model\n",
    "lr.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Checking the score on validation data\n",
    "fold_score = lr.score(X_valid, y_valid)\n",
    "\n",
    "print(f\"Validation score: {fold_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise 3: hyperparameter optimization\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e9e6fdea209d872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3(a)\n",
    "rubric={points:4}\n",
    "\n",
    "The following code varies the `max_features` hyperparameter of `CountVectorizer` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `max_features`. It also prints the results. \n",
    "\n",
    "Based on the plot/output, what value of `max_features` seems best? Briefly explain.\n",
    "\n",
    "> **Note:** the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:44:44.287278Z",
     "start_time": "2023-02-11T01:44:01.888649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "max_features = [10, 100, 1000, 10_000, 100_000]\n",
    "\n",
    "for mf in max_features:\n",
    "#     print(mf)\n",
    "    pipe = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=mf),\n",
    "        LogisticRegression(max_iter=1000),\n",
    "    )\n",
    "    cv_results = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "    train_scores.append(cv_results[\"train_score\"].mean())\n",
    "    cv_scores.append(cv_results[\"test_score\"].mean())\n",
    "\n",
    "plt.semilogx(max_features, train_scores, label=\"train\")\n",
    "plt.semilogx(max_features, cv_scores, label=\"valid\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:44:44.362037Z",
     "start_time": "2023-02-11T01:44:44.289858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>train</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.764701</td>\n",
       "      <td>0.763425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.838270</td>\n",
       "      <td>0.835671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.904380</td>\n",
       "      <td>0.889371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.951936</td>\n",
       "      <td>0.897860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.967952</td>\n",
       "      <td>0.898475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features     train        cv\n",
       "0            10  0.764701  0.763425\n",
       "1           100  0.838270  0.835671\n",
       "2          1000  0.904380  0.889371\n",
       "3         10000  0.951936  0.897860\n",
       "4        100000  0.967952  0.898475"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"max_features\": max_features, \"train\": train_scores, \"cv\": cv_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**\n",
    "\n",
    "Based on the plot, 100,000 value for the `max_features` hyperparameter seems to be the best because it gives the highest cross validation score. However, it overfits too hence some sort of reguralization might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(b)\n",
    "rubric={points:6}\n",
    "\n",
    "The following code varies the `C` hyperparameter of `LogisticRegression` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `C`. \n",
    "\n",
    "Based on the plot, what value of `C` seems best?\n",
    "\n",
    "> **Note:** the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:46:19.197166Z",
     "start_time": "2023-02-11T01:44:44.377676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "C_vals = 10.0 ** np.arange(-2, 2, 0.5)\n",
    "\n",
    "for C in C_vals:\n",
    "    #     print(C)\n",
    "    pipe = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=None),\n",
    "        LogisticRegression(max_iter=1000, C=C),\n",
    "    )\n",
    "    cv_results = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "    train_scores.append(cv_results[\"train_score\"].mean())\n",
    "    cv_scores.append(cv_results[\"test_score\"].mean())\n",
    "\n",
    "plt.semilogx(C_vals, train_scores, label=\"train\")\n",
    "plt.semilogx(C_vals, cv_scores, label=\"valid\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:46:19.256873Z",
     "start_time": "2023-02-11T01:46:19.200823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>train</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.864612</td>\n",
       "      <td>0.857969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.890316</td>\n",
       "      <td>0.876822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.919227</td>\n",
       "      <td>0.894692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.898844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967952</td>\n",
       "      <td>0.898475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.986091</td>\n",
       "      <td>0.896014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.994256</td>\n",
       "      <td>0.890355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.622777</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>0.883004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C     train        cv\n",
       "0   0.010000  0.864612  0.857969\n",
       "1   0.031623  0.890316  0.876822\n",
       "2   0.100000  0.919227  0.894692\n",
       "3   0.316228  0.941333  0.898844\n",
       "4   1.000000  0.967952  0.898475\n",
       "5   3.162278  0.986091  0.896014\n",
       "6  10.000000  0.994256  0.890355\n",
       "7  31.622777  0.996840  0.883004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"C\": C_vals, \"train\": train_scores, \"cv\": cv_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**\n",
    "***\n",
    "Based on the plots above, the best value of C is `0.316228` because it gives us the highest validation score. However This to overfits a lot, hence some other form of hyperparameter tuning might be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3(c) Hyperparameter optimization \n",
    "rubric={points:10}\n",
    "\n",
    "Start with the pipeline `pipe` below.\n",
    "\n",
    "**Your tasks:**\n",
    "- Create a `GridSearchCV` object named `grid_search` to jointly optimize `max_features` of `CountVectorizer` and `C` of `LogisticRegression` across all the combinations of values we tried above. \n",
    "- What are the best values of `max_features` and `C` according to your grid search? \n",
    "- Store them in variables `best_max_features` and `best_C`, respectively.  \n",
    "- Store the best score returned by the grid search in a variable called `best_score`. \n",
    "\n",
    "> The code might be a bit slow here. Setting `n_jobs=-1` should speed it up if you have a multi-core processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:48:41.170211Z",
     "start_time": "2023-02-11T01:46:19.262727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Max Feature: 100,000\n",
      "Best Logistic C: 0.3162\n",
      "Best Score: 0.898844\n"
     ]
    }
   ],
   "source": [
    "# Creating parameter grid\n",
    "param_grid = {\"countvectorizer__max_features\": max_features,\n",
    "              \"logisticregression__C\": C_vals}\n",
    "\n",
    "# Creating a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipe, param_grid = param_grid, n_jobs=-1)\n",
    "\n",
    "# Fitting the grid_search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtaining the best max_feature hyperparameter\n",
    "best_max_features = grid_search.best_params_['countvectorizer__max_features']\n",
    "\n",
    "# Obtainig the best `C` hyperparameter\n",
    "best_C = grid_search.best_params_['logisticregression__C']\n",
    "\n",
    "# Obtaining The Best Score\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Printing the hyperparameters and best score\n",
    "print(f'Best Max Feature: {best_max_features:,}\\n'\\\n",
    "      f'Best Logistic C: {best_C:.4f}\\n'\\\n",
    "      f'Best Score: {best_score:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3(d) Discussion \n",
    "rubric={points:4}\n",
    "\n",
    "- Do the best values of hyperparameters found by Grid Search agree with what you found in 3(a) and 3(b)? \n",
    "- **Generally speaking**, _should_ these values agree with what you found in parts  3.1 and 3.2? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Yes the hyperparameters found by Grid Search agree with what I got in 3(a) and 3(b). However, generally speaking, the values do not need to agree. This is because the approach in 3(a) only looks at the best max_features parameter on the default parameter of C, and 3b only focuses on the C hyperparameter. GridSearch on the other hand looks at all the possible compinations of the C hyperparameters and the max_features and picks the best combination. This is a more brute approach and can only provide results that are at least as good as the approach in 3a, other wise better results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(e) Test score\n",
    "rubric={points:2}\n",
    "\n",
    "- Evaluate your final model on the test set. Store the test accuracy in the variable called `test_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T01:48:41.580697Z",
     "start_time": "2023-02-11T01:48:41.174506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.90\n"
     ]
    }
   ],
   "source": [
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f\"Test Score: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3(f) Discussion of Test Score\n",
    "rubric={points:4}\n",
    "\n",
    "- How does your test accuracy compare to your validation accuracy? \n",
    "- If they are different: do you think this is because you \"overfitted on the validation set\", or simply random luck?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**\n",
    "\n",
    "The test accuracy (90%) is slightly better than the validation accuracy (89.88%). They are not significantly differnet. The test accuracy is slightly better than the validation accuracy. This an indication that the model has generalised well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Very short answer questions\n",
    "rubric={points:8}\n",
    "\n",
    "Each question is worth 2 points. Max 2 sentences per answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the problem with calling `fit_transform` on your test data with `CountVectorizer`?  \n",
    "2. If you could only access one of `predict` or `predict_proba`, which one would you choose? Briefly explain.\n",
    "3. What are two advantages of `RandomizedSearchCV` over `GridSearchCV`?\n",
    "4. Why is it important to follow the Golden Rule? If you violate it, will that give you a worse classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**\n",
    "\n",
    "\n",
    "1. `fit_transform` on test data fits the `Countvectorizer` again on the test data, which updates the parameters of the `CountVectorizer` object which is bad. Ideally, we should just fit on the train set and use the parameters to update the transform the test set\n",
    "2. I would choose `predict_proba` because, with results from `predict_proba`, I can obtain the results from `predict`. Furthermore, `predict_proba` helps give a better understanding of the model results since we know how confident out model is in an output.\n",
    "3. Randomized search is faster than gridsearch when computing. It can also find better hyperparameters since it randomly looks though different hyperparameters that are not predefined.\n",
    "4. The golden rule is very important because it helps us evaluate our model beter. While it is a great practie to follow it, saying that violeting it will give you a worst classifier might be a false statement since you might get lucky and get a good classifier without  following the golden rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
